{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b18bfd1f-ab05-4445-b449-835dbbd4a611",
   "metadata": {},
   "source": [
    "# Multi-Agency Water Quality Data from the Water Quality Portal (WQP)\n",
    "\n",
    "`dataretrieval` also allows users to access data from the [Water Quality Portal](http://www.waterqualitydata.us/). The WQP houses data from multiple agencies; while USGS data comes from the NWIS database, EPA data comes from the STORET database (this includes many state, tribal, NGO, and academic groups). The WQP brings data from all these organizations together and provides it in a single format that has a more verbose output than NWIS. To get non-NWIS data, need to use CharacteristicName instead of parameter code.\n",
    "\n",
    "\n",
    "## WQP Basic Retrievals\n",
    "\n",
    "Much like the convenience functions for NWIS, there's a simple function for retrievals if the site number and parameter code or characteristic name is known.\n",
    "\n",
    "Both `dataretrieva.nwis` and `dataretrieva.wqp` allow users to pass arguments directly to the underlying REST API's; however `wqp` tends to be more bare bones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2691dd5-8b92-482b-88e5-2646259ff690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dataretrieval import wqp\n",
    "\n",
    "[i  for i in dir(wqp) if 'get' in i or 'what' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8180785-1506-4887-9f24-8e637075cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "wqp.get_results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9018b8f-df10-4b06-8247-5112a3670aa4",
   "metadata": {},
   "source": [
    "## Large queries\n",
    "Now returning to the problem from the previous notebook,\n",
    "how might we construct a statewide query for phosphorus data?\n",
    "\n",
    "WQP, like NWIS, has it's own idiosyncrasies.\n",
    "In part because WQP's API is changing, `dataretrieval` makes less effort to hide these than for NWIS. Nevertheless, the API is very powerful if you have the doc close at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8cfe93-c16c-4cf8-834e-28b8ea96d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataretrieval.codes import fips_codes\n",
    "\n",
    "# format FIPS (state) code for WQP\n",
    "statecode = f\"US:{fips_codes['Illinois']}\"\n",
    "statecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138b32b-5f4c-471f-ad1d-34700cd075c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now query WQP by state code\n",
    "df, meta = wqp.get_results(\n",
    "    statecode=statecode,\n",
    "    pCode=\"00665\", # total phosphorus\n",
    "    minresults=\"200\",\n",
    "    providers=\"NWIS\", # STORET data don't have pcodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae9762-96fa-4beb-b549-a15b0e9cc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41574e72-c00c-4dd9-bfd0-6653980c9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = df.shape[0]\n",
    "n_sites = df['MonitoringLocationIdentifier'].unique().shape[0]\n",
    "\n",
    "print(f\"The query returned {n_samples} samples from {n_sites} monitoring sites.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de591f9e-c691-440e-9834-5a756e6f94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9395d934-39be-432e-9ae5-bd98a9b1b689",
   "metadata": {},
   "source": [
    "We'll dig into some of these details a bit more later.\n",
    "For now, let's do a little exploration.\n",
    "Let's try plotting the temporal extent of these data.\n",
    "\n",
    "First, `groupby` monitoring location, then compute the earliest date at each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba1d1ed-3c8d-480d-8bfb-51b137feb9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby = df.groupby('MonitoringLocationIdentifier')\n",
    "\n",
    "start_dates = groupby['ActivityStartDate'].apply(\n",
    "        lambda x: x.min()\n",
    ")\n",
    "\n",
    "start_dates = pd.to_datetime(start_dates)\n",
    "start_dates.name = 'start'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b48908-f465-4d70-8d0c-4f09ea9a5f2c",
   "metadata": {},
   "source": [
    "and the end dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1553c91-6303-42f7-9b90-10ddb7ab0262",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_dates = groupby['ActivityStartDate'].apply(\n",
    "        lambda x: x.max()\n",
    ")\n",
    "\n",
    "end_dates = pd.to_datetime(end_dates)\n",
    "end_dates.name = 'end'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03101db1-e775-497a-b505-4d1f828f0ffd",
   "metadata": {},
   "source": [
    "and now the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f43af2f-3c09-4941-9824-8e4fb8144440",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.concat([start_dates, end_dates], axis=1)\n",
    "dates['diff'] = dates['end'] - dates['start']\n",
    "dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2b79e9-51ec-4b23-917d-abfdcea7addb",
   "metadata": {},
   "source": [
    "Every analysis should end in a visualization,\n",
    "so here is a simple example of how we could visualize temporal data coverage in our region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d5d8b-8676-44db-8827-21ad71e1096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    " \n",
    "y_tick_labels = dates.index.values\n",
    "y_pos = np.arange(len(y_tick_labels))\n",
    " \n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(y_tick_labels)\n",
    " \n",
    "for index, row in dates.sort_values(by='start').reset_index().iterrows():\n",
    "    start_year = int(row.start.strftime(\"%Y\"))\n",
    "    duration = row['diff'].days/365\n",
    "    ax.broken_barh([(start_year, duration)], \n",
    "                    (index-0.5,0.8), \n",
    "                    facecolors =('tan'),\n",
    "                   label=row.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285c40b5-5deb-4db2-846b-9be5f63564d8",
   "metadata": {},
   "source": [
    "## STORET data\n",
    "In the last example, we queried data from NWIS using a parameter code or \"p code\",\n",
    "which are eventually going away, so we'll need to query data by other means.\n",
    "\"P codes\" can seem mysterious.\n",
    "You might think, how the heck can I remember that \"00665\" is total phosphorus,\n",
    "not to mention the other 25,000 codes?\n",
    "That's a fair criticism, but as we'll see the alternatives bring their own challenges.\n",
    "\n",
    "Before we dive in, consider these p codes:\n",
    "00665 is total phosphorus in mg/L as P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d836d13-07b2-4b0c-8d6e-0e401e4efaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataretrieval import nwis\n",
    "df, _ = nwis.get_pmcodes(\"00665\")\n",
    "df[['parameter_cd','parm_nm','parm_unit', 'SRSName']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5d127-5cec-4ad4-8f32-8e84210b866e",
   "metadata": {},
   "source": [
    "00631 is dissolved nitrate as mg/L as N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133e81e-e22f-41fb-b976-aba9fb52ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = nwis.get_pmcodes(\"00631\")\n",
    "df[['parameter_cd','parm_nm','parm_unit', 'SRSName']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed10de-5e71-4735-8f8a-66ee05e23c42",
   "metadata": {},
   "source": [
    "Each of these examples also shows the The Substance Registry Services (SRS) name,\n",
    "which is an authoritative name for substances tracked or regulated by EPA (and used by WQP).\n",
    "\n",
    "A p code doesn't doesn't tell us everything about a sample, but it tells us a lot:\n",
    "- the substance (nitrate plus nitrite)\n",
    "- what fraction (filtered, i.e, dissolved)\n",
    "- the units (mg/l as N)\n",
    "\n",
    "In other words, when we query NWIS with p codes, we filter our samples on each of these properties.\n",
    "However, when we go to WQP, we are currently limited to the SNS name, which leaves some additional work for the user. \n",
    "\n",
    "Best to demonstrate by example. Let's query STORET for data at a particular site, \n",
    "then query a co-located USGS site and note some differences\n",
    "(depending on class size, we can do this in parallel - permutations of USGS or IEPA, N or P).\n",
    "\n",
    "\n",
    "Pull up the doc if you need a refresh;\n",
    "otherwise, begin by all the characteristics at your site\n",
    "(note the first difference: \"parameters\" versus \"characteristics\")\n",
    "\n",
    "Watch out for some more typical WQP mistakes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5e93cf-f967-4596-9786-ea374a43d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = wqp.get_results(\n",
    "    siteid=\"IL_EPA_WQX-D-32\",\n",
    "    #siteid=\"05586100\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf0812-2baf-4e76-be85-549186a9cbb5",
   "metadata": {},
   "source": [
    "List all available parameters/characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c026ce-8a62-4c54-81d2-0858294385fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_list = df[\"CharacteristicName\"].unique().tolist()\n",
    "parameter_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a62b5b-d149-463b-a937-9e796ac5bc9c",
   "metadata": {},
   "source": [
    "Let's narrow our search to specific characteristics and periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d0df9-15b9-48d7-bfa6-d8718004d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "siteid=\"IL_EPA_WQX-D-32\" # Illinois EPA monitoring site on the Illinois River\n",
    "#siteid=\"USGS-05586100\" # co-located USGS site\n",
    "\n",
    "characteristic = 'Phosphorus'\n",
    "#characteristic = 'Nitrate + Nitrite'\n",
    "#characteristic = 'Inorganic nitrogen (nitrate and nitrite)'\n",
    "\n",
    "df, _ = wqp.get_results(\n",
    "    siteid=siteid,\n",
    "    characteristicName=characteristic, # Note that we can't query by fraction\n",
    "    startDateLo=\"1980-01-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319ee0cc-c485-4e7e-9c41-ae7179086a9c",
   "metadata": {},
   "source": [
    "Uh oh! Take a minute to debug what happened.\n",
    "\n",
    "Reread the doc on `wqp.get_results` or else try to recreate this query at [waterqualitydata.us](https://www.waterqualitydata.us/#advanced=true).\n",
    "\n",
    "Once you've found the mistake -- the date field was NWIS format -- rerun the query and continue on.\n",
    "\n",
    "This one was easy, but with WQP it's much easier to create erroneous queries with multiple mistakes, which can be tricky to debug.\n",
    "\n",
    "### WARNING \n",
    "WQP is a complex and changing service. Some of this pain should get better with time,\n",
    "but in the meantime, it's still a great resouce; \n",
    "just anticipate that your codes may break periodically.\n",
    "For this reason, `dataretrieval.wqp` offers fewer conveniences and instead gives a shallow wrapper around the webservice API.\n",
    "\n",
    "Back to your query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f75124f-1575-4c1e-9a54-b496c13277c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Your query returned {df.shape[0]} samples!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe6260d-9c49-46f2-a5fb-68667ea6b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ResultMeasure/MeasureUnitCode\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c844f-372e-4974-bf11-e3be06ee129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ResultSampleFractionText\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c71f58-606b-4282-98bf-9d3ffd0fb379",
   "metadata": {},
   "source": [
    "Running a through a few iterations of different characteristics and databases,\n",
    "some of the inconsistencies will quickly become apparanent. \n",
    "Each database might use a different nameing, unit, date-time convention, etc.\n",
    "Use the wrong filter for your data, and your query might accidently return no data or, worse, the wrong data.\n",
    "Be sure to watch out for this in your applications!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
